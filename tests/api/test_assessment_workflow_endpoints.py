#!/usr/bin/env python3
"""
BHIV HR Platform - Assessment & Workflow Endpoints Testing
Tests feedback, interviews, and offers endpoints individually and generates a comprehensive report.
"""

import requests
import json
import time
from datetime import datetime, timedelta
from typing import Dict, Any

# Configuration
BASE_URL = "https://bhiv-hr-gateway-ltg0.onrender.com"
API_KEY = "prod_api_key_XUqM2msdCa4CYIaRywRNXRVc477nlI3AQ-lr6cgTB2o"

HEADERS = {
    "Authorization": f"Bearer {API_KEY}",
    "Content-Type": "application/json"
}

def test_endpoint(endpoint: str, method: str = "GET", data: Dict = None) -> Dict[str, Any]:
    """Test a single endpoint and return results"""
    url = f"{BASE_URL}{endpoint}"
    
    start_time = time.time()
    
    try:
        if method == "GET":
            response = requests.get(url, headers=HEADERS, timeout=30)
        elif method == "POST":
            response = requests.post(url, headers=HEADERS, json=data, timeout=30)
        else:
            return {"status": "error", "message": f"Unsupported method: {method}"}
        
        response_time = time.time() - start_time
        
        # Try to parse JSON response
        try:
            response_data = response.json()
        except:
            response_data = response.text
        
        return {
            "status": "success" if response.status_code < 400 else "error",
            "status_code": response.status_code,
            "response_time": round(response_time, 3),
            "response_size": len(response.content),
            "response_data": response_data,
            "headers": dict(response.headers)
        }
        
    except requests.exceptions.Timeout:
        return {
            "status": "timeout",
            "message": "Request timed out after 30 seconds",
            "response_time": 30.0
        }
    except requests.exceptions.ConnectionError:
        return {
            "status": "connection_error",
            "message": "Failed to connect to the server"
        }
    except Exception as e:
        return {
            "status": "error",
            "message": str(e),
            "response_time": time.time() - start_time
        }

def main():
    """Test assessment & workflow endpoints and generate report"""
    print("Testing BHIV HR Platform Assessment & Workflow Endpoints")
    print("=" * 70)
    
    # Test endpoints configuration
    assessment_endpoints = [
        # Feedback Management
        {
            "name": "Get All Feedback",
            "endpoint": "/v1/feedback",
            "method": "GET",
            "description": "Retrieve all feedback records for candidates"
        },
        {
            "name": "Submit Feedback",
            "endpoint": "/v1/feedback",
            "method": "POST",
            "description": "Submit new feedback for a candidate",
            "test_data": {
                "candidate_id": 1,
                "job_id": 1,
                "interviewer_name": "Test Interviewer",
                "integrity_score": 4,
                "honesty_score": 5,
                "discipline_score": 4,
                "hard_work_score": 5,
                "gratitude_score": 4,
                "overall_comments": "Strong candidate with excellent values alignment"
            }
        },
        # Interview Management
        {
            "name": "Get Interviews",
            "endpoint": "/v1/interviews",
            "method": "GET",
            "description": "Retrieve all scheduled interviews"
        },
        {
            "name": "Schedule Interview",
            "endpoint": "/v1/interviews",
            "method": "POST",
            "description": "Schedule a new interview",
            "test_data": {
                "candidate_id": 1,
                "job_id": 1,
                "interviewer_name": "Test Interviewer",
                "interview_date": (datetime.now() + timedelta(days=7)).strftime("%Y-%m-%d"),
                "interview_time": "14:00",
                "interview_type": "technical",
                "location": "Virtual - Zoom",
                "notes": "Technical interview focusing on Python and system design"
            }
        },
        # Offers Management
        {
            "name": "Get All Offers",
            "endpoint": "/v1/offers",
            "method": "GET",
            "description": "Retrieve all job offers"
        },
        {
            "name": "Create Job Offer",
            "endpoint": "/v1/offers",
            "method": "POST",
            "description": "Create a new job offer",
            "test_data": {
                "candidate_id": 1,
                "job_id": 1,
                "salary_offered": 85000,
                "start_date": (datetime.now() + timedelta(days=30)).strftime("%Y-%m-%d"),
                "offer_details": "Full-time Software Engineer position with competitive benefits package",
                "benefits": "Health insurance, 401k matching, flexible PTO, remote work options"
            }
        }
    ]
    
    results = []
    
    for endpoint_config in assessment_endpoints:
        print(f"\nTesting: {endpoint_config['name']}")
        print(f"   Endpoint: {endpoint_config['method']} {endpoint_config['endpoint']}")
        
        test_data = endpoint_config.get("test_data")
        if test_data:
            print(f"   Test Data: {json.dumps(test_data, indent=2)}")
        
        result = test_endpoint(
            endpoint_config["endpoint"],
            endpoint_config["method"],
            test_data
        )
        
        result["endpoint_info"] = endpoint_config
        results.append(result)
        
        # Print immediate results
        if result["status"] == "success":
            print(f"   [OK] Status: {result['status_code']} - {result['response_time']}s")
            if isinstance(result["response_data"], dict):
                print(f"   Response keys: {list(result['response_data'].keys())}")
            elif isinstance(result["response_data"], list):
                print(f"   Response: {len(result['response_data'])} items")
            else:
                print(f"   Response size: {result['response_size']} bytes")
        else:
            print(f"   [ERROR] Status: {result['status']} - {result.get('message', 'Unknown error')}")
    
    # Generate markdown report
    generate_markdown_report(results)
    
    print(f"\nReport generated: assessment_workflow_endpoints_test_report.md")
    print("=" * 70)

def generate_markdown_report(results):
    """Generate a comprehensive markdown report"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    report = f"""# BHIV HR Platform - Assessment & Workflow Endpoints Test Report

**Generated:** {timestamp}  
**Platform:** BHIV HR Gateway Service  
**Base URL:** {BASE_URL}  
**Test Category:** Assessment & Workflow Endpoints

## üìä Test Summary

| Endpoint | Method | Status | Response Time | Status Code | Description |
|----------|--------|--------|---------------|-------------|-------------|
"""
    
    for result in results:
        endpoint_info = result["endpoint_info"]
        status_icon = "‚úÖ" if result["status"] == "success" else "‚ùå"
        status_code = result.get("status_code", "N/A")
        response_time = f"{result.get('response_time', 0):.3f}s"
        
        report += f"| `{endpoint_info['endpoint']}` | {endpoint_info['method']} | {status_icon} {result['status']} | {response_time} | {status_code} | {endpoint_info['description'][:50]}... |\n"
    
    # Calculate success rate
    success_count = sum(1 for r in results if r["status"] == "success")
    total_count = len(results)
    success_rate = (success_count / total_count) * 100
    
    report += f"\n**Overall Success Rate:** {success_count}/{total_count} ({success_rate:.1f}%)\n\n"
    
    report += "## üîç Detailed Test Results\n\n"
    
    # Group by category
    categories = {
        "Feedback Management": [r for r in results if "feedback" in r["endpoint_info"]["endpoint"]],
        "Interview Management": [r for r in results if "interviews" in r["endpoint_info"]["endpoint"]],
        "Offers Management": [r for r in results if "offers" in r["endpoint_info"]["endpoint"]]
    }
    
    for category, category_results in categories.items():
        report += f"### {category}\n\n"
        
        for result in category_results:
            endpoint_info = result["endpoint_info"]
            
            report += f"#### {endpoint_info['name']}\n\n"
            report += f"**Endpoint:** `{endpoint_info['method']} {endpoint_info['endpoint']}`  \n"
            report += f"**Description:** {endpoint_info['description']}  \n\n"
            
            if result["status"] == "success":
                report += f"**‚úÖ Test Result:** PASSED  \n"
                report += f"**Status Code:** {result['status_code']}  \n"
                report += f"**Response Time:** {result['response_time']}s  \n"
                report += f"**Response Size:** {result['response_size']} bytes  \n\n"
                
                # Add response analysis
                if isinstance(result["response_data"], dict):
                    report += "**Response Structure:**\n```json\n"
                    if len(str(result["response_data"])) > 1000:
                        report += json.dumps({k: "..." for k in list(result["response_data"].keys())[:10]}, indent=2)
                        report += "\n// ... (truncated for readability)\n"
                    else:
                        report += json.dumps(result["response_data"], indent=2)
                    report += "\n```\n\n"
                elif isinstance(result["response_data"], list):
                    report += f"**Response:** Array with {len(result['response_data'])} items  \n"
                    if result["response_data"]:
                        report += "**Sample Item:**\n```json\n"
                        report += json.dumps(result["response_data"][0], indent=2)
                        report += "\n```\n\n"
                else:
                    report += f"**Response:** `{result['response_data']}`  \n\n"
                    
                # Add test data if it was a POST request
                if endpoint_info["method"] == "POST" and "test_data" in endpoint_info:
                    report += "**Test Data Sent:**\n```json\n"
                    report += json.dumps(endpoint_info["test_data"], indent=2)
                    report += "\n```\n\n"
                    
            else:
                report += f"**‚ùå Test Result:** FAILED  \n"
                report += f"**Error:** {result.get('message', 'Unknown error')}  \n"
                if "response_time" in result:
                    report += f"**Response Time:** {result['response_time']}s  \n"
                report += "\n"
    
    # Add code structure analysis
    report += "## üèóÔ∏è Code Structure Analysis\n\n"
    report += "### Assessment & Workflow Implementation\n\n"
    report += "The assessment and workflow endpoints are implemented in the main FastAPI application with:\n\n"
    report += "- **Feedback Management System** - BHIV values-based assessment (5-point scale)\n"
    report += "- **Interview Scheduling** - Comprehensive interview management\n"
    report += "- **Offer Management** - Job offer creation and tracking\n"
    report += "- **Database Integration** - PostgreSQL with proper relationships\n"
    report += "- **Authentication** - Bearer token security for all endpoints\n\n"
    
    report += "### Key Features:\n\n"
    report += "1. **BHIV Values Assessment** - Integrity, Honesty, Discipline, Hard Work, Gratitude\n"
    report += "2. **Interview Types** - Technical, behavioral, cultural fit interviews\n"
    report += "3. **Offer Tracking** - Salary, benefits, start dates, and status\n"
    report += "4. **Data Validation** - Input validation and error handling\n"
    report += "5. **Audit Trail** - Complete tracking of assessment workflow\n\n"
    
    # Add performance analysis
    report += "## ‚ö° Performance Analysis\n\n"
    
    avg_response_time = sum(r.get("response_time", 0) for r in results if r["status"] == "success") / max(success_count, 1)
    report += f"**Average Response Time:** {avg_response_time:.3f}s  \n"
    
    fastest = min((r for r in results if r["status"] == "success"), key=lambda x: x.get("response_time", float('inf')), default=None)
    slowest = max((r for r in results if r["status"] == "success"), key=lambda x: x.get("response_time", 0), default=None)
    
    if fastest:
        report += f"**Fastest Endpoint:** `{fastest['endpoint_info']['endpoint']}` ({fastest['response_time']}s)  \n"
    if slowest:
        report += f"**Slowest Endpoint:** `{slowest['endpoint_info']['endpoint']}` ({slowest['response_time']}s)  \n"
    
    report += "\n"
    
    # Add recommendations
    report += "## üí° Recommendations\n\n"
    
    if success_rate == 100:
        report += "‚úÖ **All assessment & workflow endpoints are functioning correctly**\n\n"
        report += "- Feedback system properly implements BHIV values assessment\n"
        report += "- Interview scheduling works with proper validation\n"
        report += "- Offer management handles all required fields\n"
        report += "- Response times are acceptable for production use\n\n"
    else:
        report += f"‚ö†Ô∏è **{total_count - success_count} endpoint(s) failed testing**\n\n"
        failed_endpoints = [r for r in results if r["status"] != "success"]
        for failed in failed_endpoints:
            report += f"- `{failed['endpoint_info']['endpoint']}`: {failed.get('message', 'Unknown error')}\n"
        report += "\n"
    
    report += "### Next Steps:\n\n"
    report += "1. **Monitor Performance** - Track response times in production\n"
    report += "2. **Validate Data** - Ensure all assessment data is properly stored\n"
    report += "3. **Test Integration** - Verify workflow between feedback, interviews, and offers\n"
    report += "4. **Security Review** - Audit access controls for sensitive assessment data\n\n"
    
    # Add usage examples
    report += "## üìù Usage Examples\n\n"
    report += "### Submit Candidate Feedback\n"
    report += "```bash\n"
    report += f'curl -X POST "{BASE_URL}/v1/feedback" \\\n'
    report += f'  -H "Authorization: Bearer {API_KEY}" \\\n'
    report += '  -H "Content-Type: application/json" \\\n'
    report += '  -d {\n'
    report += '    "candidate_id": 1,\n'
    report += '    "job_id": 1,\n'
    report += '    "interviewer_name": "John Smith",\n'
    report += '    "integrity_score": 5,\n'
    report += '    "honesty_score": 4,\n'
    report += '    "discipline_score": 5,\n'
    report += '    "hard_work_score": 4,\n'
    report += '    "gratitude_score": 5,\n'
    report += '    "overall_comments": "Excellent candidate"\n'
    report += '  }\n'
    report += "```\n\n"
    
    report += "### Schedule Interview\n"
    report += "```bash\n"
    report += f'curl -X POST "{BASE_URL}/v1/interviews" \\\n'
    report += f'  -H "Authorization: Bearer {API_KEY}" \\\n'
    report += '  -H "Content-Type: application/json" \\\n'
    report += '  -d {\n'
    report += '    "candidate_id": 1,\n'
    report += '    "job_id": 1,\n'
    report += '    "interviewer_name": "Jane Doe",\n'
    report += '    "interview_date": "2024-11-01",\n'
    report += '    "interview_time": "14:00",\n'
    report += '    "interview_type": "technical"\n'
    report += '  }\n'
    report += "```\n\n"
    
    report += f"---\n\n"
    report += f"**Report Generated:** {timestamp}  \n"
    report += f"**Test Duration:** {sum(r.get('response_time', 0) for r in results):.3f}s total  \n"
    report += f"**Platform:** BHIV HR Platform v3.0.0-Phase3  \n"
    
    # Write report to file
    with open("assessment_workflow_endpoints_test_report.md", "w", encoding="utf-8") as f:
        f.write(report)

if __name__ == "__main__":
    main()