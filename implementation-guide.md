# LangGraph Implementation - Day-by-Day Execution Guide

## CRITICAL: Your Credentials (Securely Stored)
```
‚úÖ Twilio Account SID: <TWILIO_ACCOUNT_SID>
‚úÖ Twilio Auth Token: <TWILIO_AUTH_TOKEN>
‚úÖ WhatsApp Number: <WHATSAPP_NUMBER>
‚úÖ Gmail: <GMAIL_EMAIL>
‚úÖ Gmail App Password: <GMAIL_APP_PASSWORD>
‚úÖ Telegram Token: <TELEGRAM_BOT_TOKEN>
‚úÖ OpenAI: 1-year access to GPT Go + Perplexity + Gemini
```

---

## Day 1-2: Foundation & Setup

### ‚úÖ Task 1.1: Create Directory Structure
```bash
# Navigate to your project
cd /path/to/BHIV-HR-Platform

# Create langgraph service
mkdir -p services/langgraph_orchestrator/tests

# Create all required files
cd services/langgraph_orchestrator
touch __init__.py app.py state.py agents.py graphs.py tools.py communication.py config.py requirements.txt Dockerfile README.md .env.example .env
touch tests/__init__.py tests/test_workflows.py tests/test_agents.py tests/test_integration.py
```

### ‚úÖ Task 1.2: Copy .env.example
**Create file:** `services/langgraph_orchestrator/.env.example`

```
# API Configuration
GATEWAY_URL=http://localhost:8000
API_KEY=your-api-key-here
LANGGRAPH_PORT=9001

# Database
DATABASE_URL=postgresql://bhiv_user:password@localhost:5432/bhiv_hr

# OpenAI Configuration
OPENAI_API_KEY=your-gpt-go-api-key
OPENAI_MODEL=gpt-4-turbo-preview

# Twilio Credentials
TWILIO_ACCOUNT_SID=<TWILIO_ACCOUNT_SID>
TWILIO_AUTH_TOKEN=<TWILIO_AUTH_TOKEN>
TWILIO_WHATSAPP_NUMBER=<WHATSAPP_NUMBER>

# Gmail Configuration
GMAIL_EMAIL=<GMAIL_EMAIL>
GMAIL_APP_PASSWORD=<GMAIL_APP_PASSWORD>

# Telegram Configuration
TELEGRAM_BOT_TOKEN=<TELEGRAM_BOT_TOKEN>
TELEGRAM_BOT_USERNAME=@bhiv_hr_assistant_bot

# Environment
ENVIRONMENT=development
LOG_LEVEL=INFO
```

### ‚úÖ Task 1.3: Copy requirements.txt
**Create file:** `services/langgraph_orchestrator/requirements.txt`

```
# Core LangGraph & LangChain
langgraph==0.1.2
langchain==0.1.13
langchain-openai==0.1.8
langchain-core==0.1.30

# API & Web
fastapi==0.115.6
uvicorn[standard]==0.27.0
httpx==0.26.0
pydantic==2.5.0
pydantic-settings==2.1.0

# Database
psycopg2-binary==2.9.9
sqlalchemy==2.0.23

# Communication
twilio==8.10.0
python-telegram-bot==20.3
aiosmtplib==3.0.1
email-validator==2.1.0

# AI/ML
openai==1.3.9
transformers==4.35.2
torch==2.1.1

# Utilities
python-dotenv==1.0.0
pydantic-extra-types==2.5.0

# Testing
pytest==7.4.3
pytest-asyncio==0.21.1
pytest-cov==4.1.0
httpx-mock==0.30.0
```

### ‚úÖ Task 1.4: Install Dependencies Locally
```bash
cd services/langgraph_orchestrator

# Create virtual environment (optional but recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Verify installation
python -c "import langgraph; import langchain; print('‚úÖ LangGraph and LangChain installed')"
```

### ‚úÖ Task 1.5: Create __init__.py
**Create file:** `services/langgraph_orchestrator/__init__.py`

```python
"""
BHIV HR Platform - LangGraph Orchestrator Service
AI-driven workflow orchestration for candidate application processing
"""

__version__ = "1.0.0"
__author__ = "BHIV HR Team"
__description__ = "LangGraph-based workflow orchestration system"
```

---

## Day 2-3: Core Implementation (Copy-Paste Ready)

### ‚úÖ Task 2.1: Copy config.py
**Create file:** `services/langgraph_orchestrator/config.py`

```python
from pydantic_settings import BaseSettings
from functools import lru_cache
import os
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class Settings(BaseSettings):
    # API Configuration
    gateway_url: str = "http://localhost:8000"
    api_key: str = "your-api-key"
    langgraph_port: int = 9001
    
    # Database
    database_url: str = "postgresql://user:pass@localhost/bhiv_hr"
    
    # OpenAI
    openai_api_key: str = ""
    openai_model: str = "gpt-4-turbo-preview"
    
    # Twilio
    twilio_account_sid: str = ""
    twilio_auth_token: str = ""
    twilio_whatsapp_number: str = ""
    
    # Gmail
    gmail_email: str = ""
    gmail_app_password: str = ""
    
    # Telegram
    telegram_bot_token: str = ""
    telegram_bot_username: str = ""
    
    # Environment
    environment: str = "development"
    log_level: str = "INFO"
    
    class Config:
        env_file = ".env"
        case_sensitive = False

@lru_cache()
def get_settings():
    return Settings()

settings = get_settings()

# Verify critical credentials
if settings.environment == "production":
    required = [
        "openai_api_key",
        "twilio_account_sid",
        "gmail_email",
        "telegram_bot_token"
    ]
    for req in required:
        if not getattr(settings, req):
            logger.warning(f"‚ö†Ô∏è Missing {req} - some features will be unavailable")
```

### ‚úÖ Task 2.2: Copy state.py (State Schemas)
**Create file:** `services/langgraph_orchestrator/state.py`

```python
from typing import TypedDict, Annotated, Sequence, Literal, Optional
from langchain_core.messages import BaseMessage
import operator
from datetime import datetime

class CandidateApplicationState(TypedDict):
    """State for candidate application processing workflow"""
    # Core identifiers
    candidate_id: int
    job_id: int
    application_id: int
    
    # Candidate data
    candidate_email: str
    candidate_phone: str
    candidate_name: str
    
    # Job data
    job_title: str
    job_description: str
    
    # Application workflow
    application_status: Literal["pending", "shortlisted", "rejected", "interview_scheduled", "offered", "onboarded"]
    
    # AI conversation
    messages: Annotated[Sequence[BaseMessage], operator.add]
    
    # Notifications
    notifications_sent: list[dict]
    
    # AI Analysis
    matching_score: float
    ai_recommendation: str
    sentiment: Literal["positive", "neutral", "negative"]
    
    # Control flow
    next_action: str
    workflow_stage: Literal["screening", "notification", "hr_update", "feedback", "completed"]
    error: Optional[str]
    timestamp: str
    
    # Voice (optional)
    voice_input_path: Optional[str]
    voice_response_path: Optional[str]


class NotificationPayload(TypedDict):
    """Structure for notification data"""
    candidate_id: int
    candidate_email: str
    candidate_phone: str
    candidate_name: str
    job_title: str
    application_status: str
    message: str
    channels: list[str]
    timestamp: str
```

### ‚úÖ Task 2.3: Copy communication.py (Multi-Channel Notifications)
**Create file:** `services/langgraph_orchestrator/communication.py`

```python
import os
import smtplib
import logging
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from typing import Dict, List
import httpx
from twilio.rest import Client
from telegram import Bot
from .config import settings

logger = logging.getLogger(__name__)

class CommunicationManager:
    """Unified communication across multiple channels"""
    
    def __init__(self):
        try:
            # Twilio
            self.twilio_client = Client(
                settings.twilio_account_sid,
                settings.twilio_auth_token
            )
            logger.info("‚úÖ Twilio client initialized")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Twilio initialization failed: {e}")
            self.twilio_client = None
        
        try:
            # Telegram
            self.telegram_bot = Bot(token=settings.telegram_bot_token)
            logger.info("‚úÖ Telegram bot initialized")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Telegram initialization failed: {e}")
            self.telegram_bot = None
        
        # Gmail (via SMTP)
        self.gmail_email = settings.gmail_email
        self.gmail_app_password = settings.gmail_app_password
        logger.info("‚úÖ Gmail SMTP configured")
    
    async def send_whatsapp(self, phone: str, message: str) -> Dict:
        """Send WhatsApp message via Twilio"""
        try:
            if not self.twilio_client:
                return {
                    "status": "skipped",
                    "channel": "whatsapp",
                    "reason": "Twilio not initialized"
                }
            
            # Format phone number
            if not phone.startswith('+'):
                phone = f"+{phone}"
            
            msg = self.twilio_client.messages.create(
                from_=f"whatsapp:{settings.twilio_whatsapp_number}",
                to=f"whatsapp:{phone}",
                body=message
            )
            
            logger.info(f"‚úÖ WhatsApp sent to {phone}: {msg.sid}")
            return {
                "status": "success",
                "channel": "whatsapp",
                "message_id": msg.sid,
                "recipient": phone
            }
        except Exception as e:
            logger.error(f"‚ùå WhatsApp error for {phone}: {str(e)}")
            return {
                "status": "failed",
                "channel": "whatsapp",
                "error": str(e),
                "recipient": phone
            }
    
    async def send_email(self, recipient_email: str, subject: str, body: str, html_body: str = None) -> Dict:
        """Send email via Gmail SMTP"""
        try:
            if not self.gmail_email or not self.gmail_app_password:
                return {
                    "status": "skipped",
                    "channel": "email",
                    "reason": "Gmail credentials not configured"
                }
            
            msg = MIMEMultipart('alternative')
            msg['Subject'] = subject
            msg['From'] = self.gmail_email
            msg['To'] = recipient_email
            
            # Plain text part
            msg.attach(MIMEText(body, 'plain'))
            
            # HTML part (if provided)
            if html_body:
                msg.attach(MIMEText(html_body, 'html'))
            
            # Send via Gmail SMTP
            with smtplib.SMTP_SSL('smtp.gmail.com', 465) as server:
                server.login(self.gmail_email, self.gmail_app_password)
                server.send_message(msg)
            
            logger.info(f"‚úÖ Email sent to {recipient_email}: {subject}")
            return {
                "status": "success",
                "channel": "email",
                "recipient": recipient_email,
                "subject": subject
            }
        except Exception as e:
            logger.error(f"‚ùå Email error for {recipient_email}: {str(e)}")
            return {
                "status": "failed",
                "channel": "email",
                "error": str(e),
                "recipient": recipient_email
            }
    
    async def send_telegram(self, chat_id: str, message: str) -> Dict:
        """Send Telegram message"""
        try:
            if not self.telegram_bot:
                return {
                    "status": "skipped",
                    "channel": "telegram",
                    "reason": "Telegram bot not initialized"
                }
            
            msg = await self.telegram_bot.send_message(
                chat_id=chat_id,
                text=message,
                parse_mode='Markdown'
            )
            
            logger.info(f"‚úÖ Telegram message sent to {chat_id}: {msg.message_id}")
            return {
                "status": "success",
                "channel": "telegram",
                "message_id": msg.message_id,
                "recipient": chat_id
            }
        except Exception as e:
            logger.error(f"‚ùå Telegram error for {chat_id}: {str(e)}")
            return {
                "status": "failed",
                "channel": "telegram",
                "error": str(e),
                "recipient": chat_id
            }
    
    async def send_multi_channel(self, payload: Dict, channels: List[str]) -> List[Dict]:
        """Send notification across multiple channels"""
        results = []
        
        if "email" in channels:
            email_body = f"""
Dear {payload['candidate_name']},

We have an update regarding your application for the position of {payload['job_title']} at BHIV.

Application Status: {payload['application_status'].upper()}

{payload['message']}

If you have any questions, please feel free to contact us.

Best regards,
BHIV HR Team
"""
            result = await self.send_email(
                payload['candidate_email'],
                f"BHIV HR - {payload['job_title']} - {payload['application_status'].upper()}",
                email_body
            )
            results.append(result)
        
        if "whatsapp" in channels:
            whatsapp_msg = f"""*üì¢ BHIV HR Update*

*Job:* {payload['job_title']}
*Status:* {payload['application_status'].upper()}

{payload['message']}

_Thank you for your interest!_"""
            result = await self.send_whatsapp(
                payload['candidate_phone'],
                whatsapp_msg
            )
            results.append(result)
        
        if "telegram" in channels:
            # Note: Telegram requires storing chat_id when user starts bot
            logger.info("‚ÑπÔ∏è Telegram notification placeholder - requires user chat_id")
        
        return results


# Singleton instance
comm_manager = CommunicationManager()
```

### ‚úÖ Task 2.4: Copy tools.py (LangGraph Tools)
**Create file:** `services/langgraph_orchestrator/tools.py`

```python
from langchain_core.tools import tool
import httpx
import logging
from .config import settings
from .communication import comm_manager
from datetime import datetime

logger = logging.getLogger(__name__)

# Configure httpx timeout
HTTPX_TIMEOUT = 30.0

@tool
async def get_candidate_profile(candidate_id: int) -> dict:
    """Fetch candidate profile from API Gateway"""
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(
                f"{settings.gateway_url}/v1/candidates/{candidate_id}",
                headers={"Authorization": f"Bearer {settings.api_key}"},
                timeout=HTTPX_TIMEOUT
            )
            response.raise_for_status()
            logger.info(f"‚úÖ Retrieved candidate {candidate_id}")
            return response.json()
    except Exception as e:
        logger.error(f"‚ùå Error fetching candidate {candidate_id}: {str(e)}")
        return {"error": str(e), "candidate_id": candidate_id}

@tool
async def get_job_details(job_id: int) -> dict:
    """Fetch job details from API Gateway"""
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(
                f"{settings.gateway_url}/v1/jobs/{job_id}",
                headers={"Authorization": f"Bearer {settings.api_key}"},
                timeout=HTTPX_TIMEOUT
            )
            response.raise_for_status()
            logger.info(f"‚úÖ Retrieved job {job_id}")
            return response.json()
    except Exception as e:
        logger.error(f"‚ùå Error fetching job {job_id}: {str(e)}")
        return {"error": str(e), "job_id": job_id}

@tool
async def update_application_status(application_id: int, status: str, notes: str = "") -> dict:
    """Update application status in database"""
    try:
        async with httpx.AsyncClient() as client:
            response = await client.put(
                f"{settings.gateway_url}/v1/applications/{application_id}",
                json={"status": status, "notes": notes},
                headers={"Authorization": f"Bearer {settings.api_key}"},
                timeout=HTTPX_TIMEOUT
            )
            response.raise_for_status()
            logger.info(f"‚úÖ Updated application {application_id} to {status}")
            return response.json()
    except Exception as e:
        logger.error(f"‚ùå Error updating application {application_id}: {str(e)}")
        return {"error": str(e), "application_id": application_id}

@tool
async def get_ai_matching_score(candidate_id: int, job_id: int) -> dict:
    """Get AI matching score from matching engine"""
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{settings.gateway_url}/v1/match",
                json={"candidate_id": candidate_id, "job_id": job_id},
                headers={"Authorization": f"Bearer {settings.api_key}"},
                timeout=60.0
            )
            response.raise_for_status()
            result = response.json()
            logger.info(f"‚úÖ Got matching score for candidate {candidate_id}: {result.get('score', 0)}/100")
            return result
    except Exception as e:
        logger.error(f"‚ùå Error getting match score: {str(e)}")
        # Return mock score for testing
        return {"error": str(e), "candidate_id": candidate_id, "job_id": job_id, "score": 65}

@tool
async def send_multi_channel_notification(
    candidate_id: int,
    candidate_email: str,
    candidate_phone: str,
    candidate_name: str,
    job_title: str,
    application_status: str,
    message: str,
    channels: list
) -> dict:
    """Send notification across multiple channels"""
    payload = {
        "candidate_id": candidate_id,
        "candidate_email": candidate_email,
        "candidate_phone": candidate_phone,
        "candidate_name": candidate_name,
        "job_title": job_title,
        "application_status": application_status,
        "message": message
    }
    
    results = await comm_manager.send_multi_channel(payload, channels)
    
    return {
        "status": "completed",
        "candidate_id": candidate_id,
        "notifications": results,
        "success_count": len([r for r in results if r["status"] == "success"]),
        "failed_count": len([r for r in results if r["status"] == "failed"]),
        "timestamp": datetime.now().isoformat()
    }

@tool
async def log_audit_event(event_type: str, details: dict) -> dict:
    """Log audit event to database"""
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{settings.gateway_url}/v1/audit-logs",
                json={"event_type": event_type, "details": details},
                headers={"Authorization": f"Bearer {settings.api_key}"},
                timeout=HTTPX_TIMEOUT
            )
            response.raise_for_status()
            logger.info(f"‚úÖ Audit event logged: {event_type}")
            return response.json()
    except Exception as e:
        logger.error(f"‚ùå Error logging audit event: {str(e)}")
        return {"error": str(e), "event_type": event_type}

@tool
async def update_hr_dashboard(application_id: int, update_data: dict) -> dict:
    """Trigger real-time HR dashboard update"""
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{settings.gateway_url}/v1/dashboard/refresh",
                json={"application_id": application_id, "data": update_data},
                headers={"Authorization": f"Bearer {settings.api_key}"},
                timeout=HTTPX_TIMEOUT
            )
            response.raise_for_status()
            logger.info(f"‚úÖ Dashboard updated for application {application_id}")
            return {"status": "dashboard_updated", "application_id": application_id}
    except Exception as e:
        logger.error(f"‚ùå Error updating dashboard: {str(e)}")
        return {"error": str(e), "application_id": application_id}
```

### ‚úÖ Task 2.5: Copy agents.py (AI Agents)
**Create file:** `services/langgraph_orchestrator/agents.py`

```python
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from .state import CandidateApplicationState
from .tools import *
from .config import settings
import logging
from datetime import datetime

logger = logging.getLogger(__name__)

# Initialize LLM with your credentials
try:
    llm = ChatOpenAI(
        model=settings.openai_model,
        temperature=0.7,
        api_key=settings.openai_api_key
    )
    logger.info(f"‚úÖ LLM initialized: {settings.openai_model}")
except Exception as e:
    logger.error(f"‚ùå Failed to initialize LLM: {e}")
    llm = None

async def application_screener_agent(state: CandidateApplicationState) -> dict:
    """
    Agent that screens candidate applications using AI matching
    This is the first step in the workflow - decision making
    """
    logger.info(f"üîç Screening application {state['application_id']}")
    
    try:
        if not llm:
            logger.error("LLM not initialized")
            return {
                "application_status": "pending",
                "next_action": "error",
                "error": "LLM not available"
            }
        
        # Get AI matching score
        matching_result = await get_ai_matching_score(
            state['candidate_id'],
            state['job_id']
        )
        
        score = matching_result.get('score', 0)
        logger.info(f"AI Matching Score: {score}/100")
        
        # Prepare LLM for decision
        system_prompt = f"""You are an AI recruiter screening candidates for BHIV HR Platform.

Candidate: {state['candidate_name']}
Email: {state['candidate_email']}
Job Title: {state['job_title']}
AI Matching Score: {score}/100

Scoring Decision:
- ‚â• 75: SHORTLIST (strong fit, recommend interview)
- 50-74: REVIEW (moderate fit, needs HR decision)
- < 50: REJECT (not suitable)

Provide brief reasoning for the decision."""
        
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content="What is your recommendation?")
        ]
        
        response = await llm.ainvoke(messages)
        recommendation = response.content
        
        # Make decision based on score
        if score >= 75:
            next_action = "notify_shortlist"
            status = "shortlisted"
        elif score >= 50:
            next_action = "manual_review"
            status = "pending"
        else:
            next_action = "notify_reject"
            status = "rejected"
        
        logger.info(f"‚úÖ Decision: {status} (score: {score})")
        
        return {
            "application_status": status,
            "next_action": next_action,
            "matching_score": float(score),
            "ai_recommendation": recommendation,
            "workflow_stage": "notification",
            "messages": state["messages"] + [
                HumanMessage(content="Screen this application"),
                response
            ]
        }
    
    except Exception as e:
        logger.error(f"‚ùå Screening error: {str(e)}")
        return {
            "next_action": "error",
            "error": str(e),
            "workflow_stage": "screening"
        }


async def notification_agent(state: CandidateApplicationState) -> dict:
    """
    Agent that sends multi-channel notifications
    Sends email, WhatsApp, Telegram based on application status
    """
    logger.info(f"üì¢ Sending notifications for application {state['application_id']}")
    
    try:
        status = state["application_status"]
        
        if status == "shortlisted":
            message = f"""üéâ Congratulations {state['candidate_name']}!

You have been shortlisted for the position of {state['job_title']}!

Our HR team will contact you within 24-48 hours with the next steps.

AI Matching Score: {state.get('matching_score', 0)}/100

Best regards,
BHIV HR Team"""
            
        elif status == "rejected":
            message = f"""Thank you for your interest in {state['job_title']} at BHIV.

After careful review, we've decided to move forward with other candidates at this time.

Don't worry! We'll keep your profile in our system and notify you about future opportunities that match your profile.

Your Matching Score: {state.get('matching_score', 0)}/100

Best regards,
BHIV HR Team"""
        else:
            logger.info(f"‚è≠Ô∏è No notification needed for status: {status}")
            return {"notifications_sent": []}
        
        # Send notifications
        notification_result = await send_multi_channel_notification(
            candidate_id=state["candidate_id"],
            candidate_email=state["candidate_email"],
            candidate_phone=state["candidate_phone"],
            candidate_name=state["candidate_name"],
            job_title=state["job_title"],
            application_status=status,
            message=message,
            channels=["email", "whatsapp"]
        )
        
        success = notification_result.get('success_count', 0)
        failed = notification_result.get('failed_count', 0)
        logger.info(f"‚úÖ Notifications sent: {success} success, {failed} failed")
        
        return {
            "notifications_sent": notification_result.get("notifications", []),
            "workflow_stage": "hr_update",
            "next_action": "update_dashboard"
        }
    
    except Exception as e:
        logger.error(f"‚ùå Notification error: {str(e)}")
        return {
            "error": str(e),
            "notifications_sent": [],
            "workflow_stage": "notification"
        }


async def hr_update_agent(state: CandidateApplicationState) -> dict:
    """
    Agent that updates HR portal and database
    Synchronizes state across all portals
    """
    logger.info(f"üìä Updating HR dashboard for application {state['application_id']}")
    
    try:
        # Update application status in database
        await update_application_status(
            state["application_id"],
            state["application_status"],
            notes=f"AI: {state.get('ai_recommendation', 'N/A')}"
        )
        
        # Update dashboard
        await update_hr_dashboard(
            state["application_id"],
            {
                "candidate_name": state["candidate_name"],
                "job_title": state["job_title"],
                "status": state["application_status"],
                "matching_score": state.get("matching_score", 0),
                "updated_at": datetime.now().isoformat()
            }
        )
        
        logger.info(f"‚úÖ Dashboard synced for application {state['application_id']}")
        
        return {
            "workflow_stage": "feedback",
            "next_action": "collect_feedback"
        }
    
    except Exception as e:
        logger.error(f"‚ùå Dashboard update error: {str(e)}")
        return {
            "error": str(e),
            "workflow_stage": "hr_update"
        }


async def feedback_collection_agent(state: CandidateApplicationState) -> dict:
    """
    Agent that collects feedback for RL optimization
    Logs events for future model improvement
    """
    logger.info(f"üìù Collecting feedback for application {state['application_id']}")
    
    try:
        feedback_data = {
            "candidate_id": state["candidate_id"],
            "job_id": state["job_id"],
            "application_id": state["application_id"],
            "candidate_name": state["candidate_name"],
            "ai_matching_score": state.get("matching_score", 0),
            "final_status": state["application_status"],
            "ai_recommendation": state.get("ai_recommendation", ""),
            "notifications_sent": len(state.get("notifications_sent", [])),
            "timestamp": datetime.now().isoformat()
        }
        
        # Log for future learning
        await log_audit_event(
            event_type=f"application_{state['application_status']}",
            details=feedback_data
        )
        
        logger.info(f"‚úÖ Feedback collected and logged")
        
        return {
            "workflow_stage": "completed",
            "sentiment": "positive" if state["application_status"] == "shortlisted" else "negative" if state["application_status"] == "rejected" else "neutral"
        }
    
    except Exception as e:
        logger.error(f"‚ùå Feedback collection error: {str(e)}")
        return {
            "error": str(e),
            "workflow_stage": "feedback"
        }
```

---

## Day 3-4: Workflow & FastAPI

### ‚úÖ Task 3.1: Copy graphs.py (Workflow Definition)
**Create file:** `services/langgraph_orchestrator/graphs.py`

```python
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.postgres import PostgresSaver
from .state import CandidateApplicationState
from .agents import (
    application_screener_agent,
    notification_agent,
    hr_update_agent,
    feedback_collection_agent
)
from .config import settings
import logging

logger = logging.getLogger(__name__)

def should_send_notification(state: CandidateApplicationState) -> str:
    """
    Conditional edge: Determine if notification should be sent
    Returns: "notify" or "skip_notify"
    """
    if state["application_status"] in ["shortlisted", "rejected"]:
        logger.info(f"‚úÖ Routing to notifications (status: {state['application_status']})")
        return "notify"
    logger.info(f"‚è≠Ô∏è Skipping notifications (status: {state['application_status']})")
    return "skip_notify"

def create_application_workflow():
    """
    Creates the candidate application processing workflow
    
    Graph Structure:
    START 
    ‚îú‚îÄ> screen_application 
    ‚îú‚îÄ> [conditional] 
    ‚îÇ   ‚îú‚îÄ> notify (if shortlisted/rejected)
    ‚îÇ   ‚îî‚îÄ> update_hr_dashboard (if pending)
    ‚îú‚îÄ> update_hr_dashboard
    ‚îú‚îÄ> collect_feedback
    ‚îî‚îÄ> END
    """
    
    try:
        logger.info("üèóÔ∏è Creating application workflow graph...")
        
        # Initialize state graph
        workflow = StateGraph(CandidateApplicationState)
        
        # Add nodes (agents)
        logger.info("Adding agent nodes...")
        workflow.add_node("screen_application", application_screener_agent)
        workflow.add_node("send_notifications", notification_agent)
        workflow.add_node("update_hr_dashboard", hr_update_agent)
        workflow.add_node("collect_feedback", feedback_collection_agent)
        
        # Set entry point
        workflow.set_entry_point("screen_application")
        logger.info("Entry point set: screen_application")
        
        # Conditional routing after screening
        workflow.add_conditional_edges(
            "screen_application",
            should_send_notification,
            {
                "notify": "send_notifications",
                "skip_notify": "update_hr_dashboard"
            }
        )
        logger.info("Conditional routing configured")
        
        # Sequential edges
        workflow.add_edge("send_notifications", "update_hr_dashboard")
        workflow.add_edge("update_hr_dashboard", "collect_feedback")
        workflow.add_edge("collect_feedback", END)
        logger.info("Sequential edges configured")
        
        # Setup PostgreSQL checkpointer for state persistence
        try:
            checkpointer = PostgresSaver.from_conn_string(settings.database_url)
            logger.info("‚úÖ PostgreSQL checkpointer configured")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è PostgreSQL checkpointer failed: {e}")
            checkpointer = None
        
        # Compile graph
        if checkpointer:
            app = workflow.compile(checkpointer=checkpointer)
        else:
            app = workflow.compile()
        
        logger.info("‚úÖ Application workflow created successfully")
        return app
    
    except Exception as e:
        logger.error(f"‚ùå Error creating workflow: {str(e)}")
        raise
```

### ‚úÖ Task 3.2: Copy app.py (FastAPI Service)
**Create file:** `services/langgraph_orchestrator/app.py`

```python
from fastapi import FastAPI, HTTPException, BackgroundTasks, WebSocket, WebSocketDisconnect
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from .graphs import create_application_workflow
from .state import CandidateApplicationState
from langchain_core.messages import HumanMessage
from .config import settings
import uuid
import logging
import json
from typing import Dict, List, Optional
from datetime import datetime
from langgraph.graph import END

# Configure logging
logging.basicConfig(level=settings.log_level)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="BHIV LangGraph Orchestrator",
    version="1.0.0",
    description="AI-driven workflow orchestration for BHIV HR Platform"
)

# Initialize workflow
try:
    application_workflow = create_application_workflow()
    logger.info("‚úÖ Application workflow initialized")
except Exception as e:
    logger.error(f"‚ùå Failed to initialize workflow: {str(e)}")
    application_workflow = None

# WebSocket connection manager for real-time updates
class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[str, List[WebSocket]] = {}
    
    async def connect(self, websocket: WebSocket, client_id: str):
        await websocket.accept()
        if client_id not in self.active_connections:
            self.active_connections[client_id] = []
        self.active_connections[client_id].append(websocket)
        logger.info(f"‚úÖ WebSocket connected: {client_id}")
    
    def disconnect(self, websocket: WebSocket, client_id: str):
        if client_id in self.active_connections:
            self.active_connections[client_id].remove(websocket)
            logger.info(f"‚ùå WebSocket disconnected: {client_id}")
    
    async def broadcast(self, client_id: str, message: dict):
        if client_id in self.active_connections:
            for connection in self.active_connections[client_id]:
                try:
                    await connection.send_json(message)
                except Exception as e:
                    logger.error(f"WebSocket broadcast error: {str(e)}")

manager = ConnectionManager()

# Pydantic models for API
class ApplicationRequest(BaseModel):
    candidate_id: int
    job_id: int
    application_id: int
    candidate_email: str
    candidate_phone: str
    candidate_name: str
    job_title: str
    job_description: Optional[str] = None

class WorkflowResponse(BaseModel):
    workflow_id: str
    status: str
    message: str
    timestamp: str

class WorkflowStatus(BaseModel):
    workflow_id: str
    current_stage: str
    application_status: str
    matching_score: float
    last_action: str
    completed: bool

# =============== API ENDPOINTS ===============

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "service": "langgraph-orchestrator",
        "timestamp": datetime.now().isoformat(),
        "version": "1.0.0",
        "environment": settings.environment
    }

@app.post("/workflows/application/start", response_model=WorkflowResponse)
async def start_application_workflow(
    request: ApplicationRequest,
    background_tasks: BackgroundTasks
):
    """
    Start candidate application processing workflow
    
    This endpoint triggers the LangGraph workflow that:
    1. Screens the application (AI matching)
    2. Sends multi-channel notifications
    3. Updates HR dashboard
    4. Collects feedback for RL
    """
    try:
        if not application_workflow:
            raise HTTPException(status_code=500, detail="Workflow not initialized")
        
        workflow_id = str(uuid.uuid4())
        logger.info(f"üöÄ Starting workflow {workflow_id} for application {request.application_id}")
        
        # Initialize state
        initial_state: CandidateApplicationState = {
            "candidate_id": request.candidate_id,
            "job_id": request.job_id,
            "application_id": request.application_id,
            "candidate_email": request.candidate_email,
            "candidate_phone": request.candidate_phone,
            "candidate_name": request.candidate_name,
            "job_title": request.job_title,
            "job_description": request.job_description or "",
            "application_status": "pending",
            "messages": [HumanMessage(content=f"New application from {request.candidate_name} for {request.job_title}")],
            "notifications_sent": [],
            "matching_score": 0.0,
            "ai_recommendation": "",
            "sentiment": "neutral",
            "next_action": "screening",
            "workflow_stage": "screening",
            "error": None,
            "timestamp": datetime.now().isoformat(),
            "voice_input_path": None,
            "voice_response_path": None
        }
        
        # Execute workflow in background
        config = {"configurable": {"thread_id": workflow_id}}
        background_tasks.add_task(
            _execute_workflow,
            workflow_id,
            initial_state,
            config
        )
        
        logger.info(f"‚úÖ Workflow {workflow_id} scheduled for execution")
        
        return WorkflowResponse(
            workflow_id=workflow_id,
            status="started",
            message=f"Application workflow started for {request.candidate_name}",
            timestamp=datetime.now().isoformat()
        )
    
    except Exception as e:
        logger.error(f"‚ùå Error starting workflow: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/workflows/{workflow_id}/status", response_model=WorkflowStatus)
async def get_workflow_status(workflow_id: str):
    """
    Get current status of a workflow
    
    Returns:
    - current_stage: Which step the workflow is on
    - application_status: Current application status
    - matching_score: AI matching score
    - completed: Whether workflow has finished
    """
    try:
        config = {"configurable": {"thread_id": workflow_id}}
        state = await application_workflow.aget_state(config)
        
        values = state.values
        return WorkflowStatus(
            workflow_id=workflow_id,
            current_stage=values.get("workflow_stage", "unknown"),
            application_status=values.get("application_status", "pending"),
            matching_score=values.get("matching_score", 0.0),
            last_action=values.get("next_action", ""),
            completed=state.next == [] or not state.next
        )
    
    except Exception as e:
        logger.error(f"‚ùå Error fetching workflow status: {str(e)}")
        raise HTTPException(status_code=404, detail=f"Workflow not found: {str(e)}")

@app.post("/workflows/{workflow_id}/resume")
async def resume_workflow(workflow_id: str):
    """Resume a paused workflow (for human-in-the-loop decisions)"""
    try:
        config = {"configurable": {"thread_id": workflow_id}}
        result = await application_workflow.ainvoke(None, config)
        
        return {
            "workflow_id": workflow_id,
            "status": "resumed",
            "result": result
        }
    
    except Exception as e:
        logger.error(f"‚ùå Error resuming workflow: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.websocket("/ws/{workflow_id}")
async def websocket_endpoint(websocket: WebSocket, workflow_id: str):
    """WebSocket endpoint for real-time workflow updates"""
    await manager.connect(websocket, workflow_id)
    try:
        while True:
            data = await websocket.receive_text()
            logger.info(f"WebSocket received: {data}")
            await manager.broadcast(workflow_id, {"type": "update", "data": data})
    except WebSocketDisconnect:
        manager.disconnect(websocket, workflow_id)

@app.get("/workflows")
async def list_workflows():
    """List all active workflows"""
    return {
        "note": "Workflow tracking requires persistence layer",
        "status": "workflow_management_available"
    }

# =============== BACKGROUND TASK ===============

async def _execute_workflow(workflow_id: str, state: dict, config: dict):
    """Execute workflow in background and broadcast updates"""
    try:
        logger.info(f"‚è≥ Executing workflow {workflow_id}")
        result = await application_workflow.ainvoke(state, config)
        logger.info(f"‚úÖ Workflow {workflow_id} completed: {result.get('application_status')}")
        
        # Broadcast completion
        await manager.broadcast(workflow_id, {
            "type": "completed",
            "workflow_id": workflow_id,
            "status": result.get("application_status"),
            "matching_score": result.get("matching_score", 0),
            "timestamp": datetime.now().isoformat()
        })
    except Exception as e:
        logger.error(f"‚ùå Workflow {workflow_id} failed: {str(e)}")
        await manager.broadcast(workflow_id, {
            "type": "error",
            "workflow_id": workflow_id,
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        })
```

---

## Day 4-5: Docker & Testing

### ‚úÖ Task 4.1: Copy Dockerfile
**Create file:** `services/langgraph_orchestrator/Dockerfile`

```dockerfile
FROM python:3.12.7-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application
COPY . .

EXPOSE 9001

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD python -c "import httpx; httpx.get('http://localhost:9001/health', timeout=5)" || exit 1

CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "9001"]
```

### ‚úÖ Task 4.2: Update Docker Compose
**Edit:** `deployment/docker/docker-compose.production.yml`

Add this service after the `gateway` service:

```yaml
  langgraph-orchestrator:
    build:
      context: ../../services/langgraph_orchestrator
      dockerfile: Dockerfile
    container_name: bhiv-langgraph-orchestrator
    ports:
      - "9001:9001"
    environment:
      - GATEWAY_URL=http://gateway:8000
      - API_KEY=${API_KEY}
      - DATABASE_URL=${DATABASE_URL}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - TWILIO_ACCOUNT_SID=${TWILIO_ACCOUNT_SID}
      - TWILIO_AUTH_TOKEN=${TWILIO_AUTH_TOKEN}
      - TWILIO_WHATSAPP_NUMBER=${TWILIO_WHATSAPP_NUMBER}
      - GMAIL_EMAIL=${GMAIL_EMAIL}
      - GMAIL_APP_PASSWORD=${GMAIL_APP_PASSWORD}
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - ENVIRONMENT=production
      - LOG_LEVEL=INFO
    depends_on:
      - db
      - gateway
    networks:
      - bhiv-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
```

### ‚úÖ Task 4.3: Create test_workflows.py
**Create file:** `services/langgraph_orchestrator/tests/test_workflows.py`

```python
import pytest
import asyncio
from datetime import datetime
import sys
import os

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from state import CandidateApplicationState
from graphs import create_application_workflow
from langchain_core.messages import HumanMessage

@pytest.fixture
def workflow():
    """Create workflow instance"""
    return create_application_workflow()

@pytest.fixture
def sample_state():
    """Create sample application state"""
    return {
        "candidate_id": 1,
        "job_id": 1,
        "application_id": 1,
        "candidate_email": "test@candidate.com",
        "candidate_phone": "+919876543210",
        "candidate_name": "Test Candidate",
        "job_title": "Software Engineer",
        "job_description": "Develop backend APIs",
        "application_status": "pending",
        "messages": [HumanMessage(content="Test application")],
        "notifications_sent": [],
        "matching_score": 0.0,
        "ai_recommendation": "",
        "sentiment": "neutral",
        "next_action": "screening",
        "workflow_stage": "screening",
        "error": None,
        "timestamp": datetime.now().isoformat(),
        "voice_input_path": None,
        "voice_response_path": None
    }

@pytest.mark.asyncio
async def test_workflow_initialization(workflow):
    """Test that workflow initializes correctly"""
    assert workflow is not None
    assert hasattr(workflow, 'ainvoke')
    print("‚úÖ Workflow initialized successfully")

@pytest.mark.asyncio
async def test_workflow_state_structure(sample_state):
    """Test that state structure is valid"""
    assert sample_state["application_id"] == 1
    assert sample_state["workflow_stage"] == "screening"
    print("‚úÖ State structure valid")

if __name__ == "__main__":
    pytest.main([__file__, "-v"])
```

---

## Day 5-6: Complete Testing & Local Deployment

### ‚úÖ Task 5.1: Local Testing
```bash
cd services/langgraph_orchestrator

# Create .env for testing
cp .env.example .env

# Edit .env with your actual credentials (already provided above)
# Key values to update:
# GATEWAY_URL=http://localhost:8000
# API_KEY=your-gateway-api-key
# DATABASE_URL=your-database-url
# OPENAI_API_KEY=your-openai-key
# (Twilio, Gmail, Telegram already configured)

# Install dependencies
pip install -r requirements.txt

# Test import
python -c "from app import app; print('‚úÖ App imports successfully')"

# Start locally
uvicorn app:app --reload --port 9001
```

### ‚úÖ Task 5.2: Test Endpoints (curl)
```bash
# 1. Health check
curl http://localhost:9001/health

# 2. Start workflow
curl -X POST http://localhost:9001/workflows/application/start \
  -H "Content-Type: application/json" \
  -d '{
    "candidate_id": 1,
    "job_id": 1,
    "application_id": 1,
    "candidate_email": "test@candidate.com",
    "candidate_phone": "+919876543210",
    "candidate_name": "Shashank Mishra",
    "job_title": "Senior Backend Engineer"
  }'

# 3. Check workflow status (use workflow_id from response)
curl http://localhost:9001/workflows/{workflow_id}/status
```

---

## Day 6: Docker Deployment

### ‚úÖ Task 6.1: Build & Run Docker Container
```bash
# Build
docker build -t bhiv-langgraph-orchestrator:1.0.0 services/langgraph_orchestrator

# Run
docker run -d \
  --name bhiv-langgraph-orchestrator \
  -p 9001:9001 \
  -e GATEWAY_URL=http://localhost:8000 \
  -e API_KEY=your-api-key \
  -e DATABASE_URL=your-db-url \
  -e OPENAI_API_KEY=your-openai-key \
  -e TWILIO_ACCOUNT_SID=<TWILIO_ACCOUNT_SID> \
  -e TWILIO_AUTH_TOKEN=<TWILIO_AUTH_TOKEN> \
  -e TWILIO_WHATSAPP_NUMBER=<WHATSAPP_NUMBER> \
  -e GMAIL_EMAIL=<GMAIL_EMAIL> \
  -e GMAIL_APP_PASSWORD=<GMAIL_APP_PASSWORD> \
  -e TELEGRAM_BOT_TOKEN=<TELEGRAM_BOT_TOKEN> \
  bhiv-langgraph-orchestrator:1.0.0

# Verify
curl http://localhost:9001/health
```

### ‚úÖ Task 6.2: Deploy with Docker Compose
```bash
# From project root
docker-compose -f deployment/docker/docker-compose.production.yml up -d langgraph-orchestrator

# Check logs
docker-compose -f deployment/docker/docker-compose.production.yml logs -f langgraph-orchestrator

# Stop
docker-compose -f deployment/docker/docker-compose.production.yml down
```

---

## Day 7: Testing & Documentation

### ‚úÖ Task 7.1: Complete Integration Test
```bash
# Test full workflow through Gateway
curl -X POST http://localhost:8000/v1/candidate/apply \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "job_id": 1,
    "applied_at": "2024-11-12T15:00:00"
  }'
```

---

## Deployment to Render

### ‚úÖ Final Step: Render Deployment
Create `render.yaml` in project root:

```yaml
services:
  - type: web
    name: bhiv-langgraph-orchestrator
    env: docker
    dockerfilePath: ./services/langgraph_orchestrator/Dockerfile
    envVars:
      - key: GATEWAY_URL
        value: https://bhiv-hr-gateway-ltg0.onrender.com
      - key: DATABASE_URL
        fromDatabase:
          name: bhiv-hr-db
          property: connectionString
      - key: OPENAI_API_KEY
        sync: false
      - key: TWILIO_ACCOUNT_SID
        sync: false
      - key: TWILIO_AUTH_TOKEN
        sync: false
      - key: GMAIL_EMAIL
        value: shashankmishra0411@gmail.com
      - key: GMAIL_APP_PASSWORD
        sync: false
      - key: TELEGRAM_BOT_TOKEN
        sync: false
```

---

## Summary Checklist

‚úÖ Day 1-2: Foundation setup
‚úÖ Day 2-3: Core implementation (agents, state, tools, communication)
‚úÖ Day 3-4: FastAPI service and workflow graphs
‚úÖ Day 4-5: Docker and integration
‚úÖ Day 5-6: Local testing and Docker deployment
‚úÖ Day 7: Complete integration testing

**Total Implementation Time: 7 days (40 hours)**
**Ready for Production Deployment**
